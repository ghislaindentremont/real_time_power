---
title: "Bayesian Analysis"
author: "Ghislain d'Entremont"
output:
  html_document: default
  html_notebook: default
---

# Load and Tidy Data

##### Load

```{r}
# load packages we'll use ----
library(tidyverse)
library(rstan)
rstan_options(auto_write = TRUE)

library(devtools)
library(ezStan)
```

##### Read 

We read in the data and look at it.

```{r}
dat = readr::read_csv('dat.csv')
View(dat)
```

##### Sort

We sort the data by subject (id).

```{r}
dat %>%
	dplyr::arrange(
		subj
	) -> dat
```

##### Within Contrasts

We generate a within-subject contrast matrix. This matrix accounts for all the groupins of taks, laterality, and trial.

```{r}
W = get_contrast_matrix(
	data = dat
	, formula = ~  task * trial * laterality 
)
View(W)
```

##### Between Contrasts

I don't actually have any between-subject variables for the time being. Therefore, this matrix is just a single columns of ones.

```{r}
dat %>%
	dplyr::group_by(
		subj
	) %>%
	dplyr::summarize() %>% #View()
	get_contrast_matrix(
		formula = ~ 1
	) -> B
View(B)
```

# Sample Posterior

### Run model and Save

I ran the model on a 16 core vCPU through Google Cloud Compute Engine. 

```{r}
#package in list for Stan
data_for_stan = list(
	#nTrials: num trials
	nTrials = nrow(dat)
	#power: power outcomes
	, power = scale(dat$log_relative_power)[,1] #scaling for easy priors
	#nS: num subjects
	, nS = length(unique(dat$subj))
	#S: trial-by-trial subject labels
	, S = as.numeric(factor(dat$subj))
	#nWmpower: num within predictors on mean power
	, nWmpower = ncol(W)
	#nBmpower: num group predictors on mean power
	, nBmpower = ncol(B)
	#nWspower: num within predictors on sd power
	, nWspower = ncol(W)
	#nBspower: num group predictors on sd power
	, nBspower = ncol(B)
	#Wmpower: within predictors for mean power
	, Wmpower = W
	#Bmpower: between predictors for mean power
	, Bmpower = B
	#Wspower: within predictors for sd power
	, Wspower = W #for just intercepts do: matrix(W[,1],ncol=1)
	#Bspower: between predictors for sd power
	, Bspower = B #for just intercepts do: matrix(B[,1],ncol=1)
)


# # Compile & sample the model ----
# post_c = rstan::stan(
# 	file = 'bayesian_analysis.stan'
# 	, data = data_for_stan
# 	, seed = 1
# 	, chains = 4
# 	, cores = 4 #set this to # of physical cores on your system
# 	, iter = 2e3
# 	, init = 0
# 	, pars = c('normal01','cors_helper') #don't bother saving these variables
# 	, include = FALSE
# )
# save(post_c,file='post_c.rdata')
```

### Scaled Output

##### Scaled population coefficient means

The posterior estimates are all scaled. We do see that all parameters have an Rhat of 1, and have an effective N above 1000. The exception is the intercept term of the coefficient means (i.e. the overall mean), with a little over 600 effective samples.  

It took approximately 20 hours to run 2000 iterations of the model on 16 chains (~20 hours per chain).  

We can interpret the scaled effects to the extent that they are credibly non-zero. We see effects of task (negative), trial (negative), laterality (negative), task:laterality (negative), and the three-way interaction. Each are in line with the population parameters that went into generating the current data.

NOTE: the task and laterality factors are of opposite sign of how they were defined in 'create_data' because of the way the W contrast matrix is generated. The three-way interaction shown below is still has the proper sign because the flipped signs of task and laterality cancel each other in the making of the three-way interaction contrast. 

```{r}
load('post_c.rdata')
summary(rowSums(get_elapsed_time(post_c)/60/60))

# this is still scaled
stan_summary(
	from_stan = post_c
	, par = 'coefMpower'
	, W = W
	, B = B
)
```

##### Log scaled noise coefficients

The effect of task on noise is notable (greater noise in the ME task). The only other credible effect is that of trial:laterality. This effect is spurious since no such effect was set in the population parameters, in the making of the data.

```{r}
stan_summary(
	from_stan = post_c
	, par = 'coefSpower'
	, W = W
	, B = B
)
```

##### Scaled population coefficient SDs

The scaled versions of these SDs are not particularly meaningful. 

```{r}
stan_summary(
	from_stan = post_c
	, par = 'sdsW'
)
```

##### Correlations

Of the 16 choose 2 = 120 possible correlations, only three were set to be non-zero: the correlation of the intercept with each main effect. The first three entries of the correlation output indicate that two of these three correlations were detected by the model using 95% cut-offs. The actual population correlation magnitudes were easily included in all three credible intervals. Of note is that there was only one spurious correlation (4~9).

```{r}
stan_summary(
	from_stan = post_c
	, par = 'corsW'
	, is_cor = T
)
```

### Scaled condition estimates

##### Scaled population means

The three-way interaction is very apparent (i.e. ME makes the increase of LI with trial greater than does MI). The two-interaction between trial and laterality is also rather clear since the effect of trial on laterality is so pronounced in the ME condition (i.e. it is generating the two-way interaction, despite an opposing interaction in the MI condition). All three main effects are also clear to see in timeseries plot below.  

Of note is the fact that these condition-wise estimates are created by using the median of the intercept coefficient instead of it's full distribution. This removes the uncertainty associated with the intercept so that the credible intervals can be more appropriately interpreted as measures of uncertainty associated with the effects. Indeed, the effects are primarily of interest in this context.

```{r}
cp = get_condition_post(
	from_stan = post_c
	, par = 'coefMpower'
	, W = W
	, B = B
	, collapse_intercept_to_median = T 
)

cp %>%
	dplyr::group_by(
		task
		, trial
		, laterality
	) %>%
	dplyr::summarise(
		med = median(value)
		, lo95 = quantile(value,.025)
		, hi95 = quantile(value,.975)
		, lo50 = quantile(value,.25)
		, hi50 = quantile(value,.75)
	) %>%
	ggplot() +
  geom_line(aes(x=trial, y=med, color = laterality))+
  geom_line(aes(x=trial, y=hi95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=lo95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=hi50, color = laterality), linetype = "dashed")+
  geom_line(aes(x=trial, y=lo50, color = laterality), linetype = "dashed")+
	facet_grid(
		. ~ task 
	)+
  xlab("total trial")+
  ylab("scaled log relative power")
```

##### Log scaled noise coefficients

The plot reveals rather clearly a main effect of task on noise such that data collected from MI conditions are noisier than those collected from MI conditions (i.e. the log scaled noise is less negative). We see how the spurious trial:laterality interaction came out: LI flips as a function of trials. 

```{r}
cps = get_condition_post(
	from_stan = post_c
	, par = 'coefSpower'
	, W = W
	, B = B
	, collapse_intercept_to_median = T  # I'm assuming that we do this to get rid of the uncertainty associated with the intercept so that we can focus more on the uncertainty associated with the effects.
)

cps %>%
	dplyr::group_by(
		task
		, trial
		, laterality
	) %>%
	dplyr::summarise(
		med = median(value)
		, lo95 = quantile(value,.025)
		, hi95 = quantile(value,.975)
		, lo50 = quantile(value,.25)
		, hi50 = quantile(value,.75)
	) %>%
	ggplot() +
  geom_line(aes(x=trial, y=med, color = laterality))+
  geom_line(aes(x=trial, y=hi95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=lo95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=hi50, color = laterality), linetype = "dashed")+
  geom_line(aes(x=trial, y=lo50, color = laterality), linetype = "dashed")+
	facet_grid(
		. ~ task 
	) + 
  xlab("total trial")+
  ylab("log of scaled noise")
```

### Unscaled output

##### Population means

The 95% CIs of the parameter estimates capture all the true population coefficients. This corroborates the findings from the 95% 'null hypothesis' approach to examining the effects we applied for the scaled coefficients.

```{r}
coefMpower_scaled = stan_summary(
	from_stan = post_c
	, par = 'coefMpower'
	, W = W
	, B = B
)

coefMpower = coefMpower_scaled[,1:3] * sd(dat$log_relative_power)
coefMpower[1,] = coefMpower[1,] + mean(dat$log_relative_power) 
coefMpower
```

##### Population coefficient SDs

These just overestimate the trial coefficient variability and underestimate the laterality coefficient variability. OTherwise, the 95% CIs appear to capture all the coefficient SDs (1-8). We will ignore the noise SDs.

```{r}
sdsW_scaled = stan_summary(
	from_stan = post_c
	, par = 'sdsW'
)

sdsW = sdsW_scaled[,1:3] * sd(dat$log_relative_power)
row.names(sdsW) = c(rep(row.names(coefMpower),2))
sdsW
```

### Condition estimates

##### Population means

These unsclaled graphs are virtually identical to those that are scaled. The difference is in the scale of the y-axis. Indeed, the credible intervals appear to capture the condition-wise means that were set (indirectly) in the creation of the data. Of course, the three-way interaction is particularly apparent (mainly because its effect size is so large). 

```{r}
SD = sd(dat$log_relative_power)
M = mean(dat$log_relative_power)

cp %>%
	dplyr::group_by(
		task
		, trial
		, laterality
	) %>%
	dplyr::summarise(
		med = median(value) * SD + M
		, lo95 = quantile(value,.025) * SD + M
		, hi95 = quantile(value,.975) * SD + M
		, lo50 = quantile(value,.25) * SD + M
		, hi50 = quantile(value,.75) * SD + M
	) %>%
	ggplot() +
  geom_line(aes(x=trial, y=med, color = laterality))+
  geom_line(aes(x=trial, y=hi95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=lo95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=hi50, color = laterality), linetype = "dashed")+
  geom_line(aes(x=trial, y=lo50, color = laterality), linetype = "dashed")+
	facet_grid(
		. ~ task
	)+
  ylab("population mean log relative power")
```

##### Noise values

The model appears to caputre the set population noise estimates extremely well (look at lognormal graphs from 'create_data').

```{r}
cps %>%
	dplyr::group_by(
		task
		, trial
		, laterality
	) %>%
	dplyr::summarise(
		med = exp(median(value)) * SD
		, lo95 = exp(quantile(value,.025)) * SD
		, hi95 = exp(quantile(value,.975)) * SD
		, lo50 = exp(quantile(value,.25)) * SD
		, hi50 = exp(quantile(value,.75)) * SD
	) %>%
	ggplot() +
  geom_line(aes(x=trial, y=med, color = laterality))+
  geom_line(aes(x=trial, y=hi95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=lo95, color = laterality), linetype = "dotted")+
  geom_line(aes(x=trial, y=hi50, color = laterality), linetype = "dashed")+
  geom_line(aes(x=trial, y=lo50, color = laterality), linetype = "dashed")+
	facet_grid(
		. ~ task 
	) + 
  ylab("population noise (log relative power)")
```

